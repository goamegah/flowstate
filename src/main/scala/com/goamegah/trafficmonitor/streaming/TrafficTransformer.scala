package com.goamegah.trafficmonitor.streaming

import org.apache.spark.sql.functions._
import org.apache.spark.sql.{DataFrame, SparkSession}

object TrafficTransformer {

  def transform(inputDF: DataFrame)(implicit spark: SparkSession): DataFrame = {
    import spark.implicits._

    println("[ðŸ”§] Ã‰tape 1 - DonnÃ©es brutes (streaming)")
    inputDF.printSchema()
    // ðŸš« .count() interdit en streaming
    // ðŸš« .show() interdit en streaming

    // Ã‰tape 2 - Explosion du champ `results`
    val explodedDF = inputDF
      .filter(col("results").isNotNull && size(col("results")) > 0)
      .withColumn("result", explode(col("results")))

    println("[ðŸ§¨] Ã‰tape 2 - AprÃ¨s explosion de 'results'")
    explodedDF.printSchema()

    // Ã‰tape 3 - SÃ©lection des colonnes utiles
    val selectedDF = explodedDF.selectExpr("result.*")

    println("[ðŸ“Š] Ã‰tape 3 - AprÃ¨s sÃ©lection des champs")
    selectedDF.printSchema()

    // Ã‰tape 4 - Transformation : ajout lat/lon et filtrage
    val transformedDF = selectedDF
      .withColumn("lat", col("geo_point_2d.lat"))
      .withColumn("lon", col("geo_point_2d.lon"))
      .drop("geo_point_2d")
      .filter(col("datetime").isNotNull)

    println("[ðŸ§¼] Ã‰tape 4 - AprÃ¨s nettoyage/filtrage final")
    transformedDF.printSchema()

    transformedDF
  }
}
